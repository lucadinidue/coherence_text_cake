{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-15T09:50:59.333414551Z",
     "start_time": "2024-01-15T09:50:59.168624137Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b062b-fa0f-422a-acbc-62e4ae42d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/ted/en.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685091fa678283c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'microsoft/deberta-v3-xsmall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5210adeda48b7af",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e0dd4-e62b-4dab-9b34-ab2e298ba229",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('csv', data_files=data_path, sep='\\t', converters={'sentences': ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963b8e8-fb6d-4324-8db2-1ba6f79ef817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, tokenizer):\n",
    "    dataset = dataset['train'].remove_columns('sub_sentences')\n",
    "\n",
    "    def concatenate_sentences(example):\n",
    "        example['sentences'] = ' '.join(example['sentences'])\n",
    "        return example\n",
    "    \n",
    "    dataset = dataset.map(concatenate_sentences, \n",
    "                          desc='Concatenatings passage sentences.')\n",
    "\n",
    "    def tokenize_dataset(examples):\n",
    "        tokenized_texts = tokenizer(examples['sentences'], padding=True, max_length=256, truncation=True)\n",
    "        return tokenized_texts\n",
    "\n",
    "    tokenized_dataset = dataset.map(\n",
    "            tokenize_dataset,\n",
    "            batched=True,\n",
    "            remove_columns=dataset.column_names,\n",
    "            desc=\"Running tokenizer on dataset\",\n",
    "        )\n",
    "\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a796e8e-d620-451d-9294-92de76aac923",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = preprocess_dataset(dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b18170-3ddc-4f33-93d3-9f0d1549462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c992f-05e0-43ec-ac1a-b2e5caa6c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10983004-af81-469d-8846-c398d22b431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = default_data_collator\n",
    "\n",
    "dataloader = DataLoader(dataset, shuffle=False, collate_fn=data_collator, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8b8ae-1c28-4322-b464-a1ead56e4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa31627-0f8b-40e7-bb98-156a22735c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        # num_layers, batch_size, max_seq_len (max 215), hidden_size\n",
    "        hidden_states = model(**batch)['hidden_states']\n",
    "        non_pad_tokens = batch['attention_mask'].sum(axis=1)\n",
    "        # batch_size, num_layers, max_seq_len, hidden_size\n",
    "        hidden_states = torch.stack(hidden_states, dim=1)\n",
    "        for batch_idx in range(hidden_states.shape[0]):\n",
    "            passage_hidden_states = hidden_states[batch_idx, :, :non_pad_tokens[batch_idx], :]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef18b51-8eef-4f79-a9a6-d2005f656950",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da583e-154f-433e-8191-045467475ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69408aa-e2d9-4452-b045-84a1c01a2aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
